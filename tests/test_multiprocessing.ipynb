{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实现多进程的两种方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun1(name):\n",
    "    print('测试%s多进程 \\n' %name)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    process_list = []\n",
    "    for i in range(5):  #开启5个子进程执行fun1函数\n",
    "        p = mp.Process(target=fun1,args=('Python',)) #实例化进程对象\n",
    "        p.start()\n",
    "        process_list.append(p)\n",
    "\n",
    "    for i in process_list:\n",
    "        p.join()\n",
    "\n",
    "    print('结束测试')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyProcess(mp.Process): #继承Process类\n",
    "    def __init__(self,name):\n",
    "        super(MyProcess,self).__init__()\n",
    "        self.name = name\n",
    "\n",
    "    def run(self):\n",
    "        print('测试%s多进程\\n' % self.name)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    process_list = []\n",
    "    for i in range(5):  #开启5个子进程执行fun1函数\n",
    "        p = MyProcess('Python') #实例化进程对象\n",
    "        p.start()\n",
    "        process_list.append(p)\n",
    "\n",
    "    for i in process_list:\n",
    "        p.join()\n",
    "\n",
    "    print('结束测试')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 关于进程池的使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num : 0\n",
      "num : 1\n",
      "num : 2\n",
      "\n",
      "\n",
      "\n",
      "num : 3\n",
      "num : 4\n",
      "\n",
      "\n",
      "num : 5\n",
      "\n",
      "======  apply_async  ======\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def show(num):\n",
    "    print('num : {}\\n'.format(num))\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    pool = mp.Pool(processes = 3)\n",
    "    for i in range(6):\n",
    "        # 维持执行的进程总数为processes，当一个进程执行完毕后会添加新的进程进去\n",
    "        pool.apply_async(show, args=(i, ))\n",
    "    print('======  apply_async  ======')\n",
    "    pool.close()\n",
    "    #调用join之前，先调用close函数，否则会出错。执行完close后不会有新的进程加入到pool,join函数等待所有子进程结束\n",
    "    pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "import time\n",
    "def test(p):\n",
    "       print(p)\n",
    "       time.sleep(0.1)\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    pool = Pool(processes=10)\n",
    "    for i in range(100):\n",
    "        '''\n",
    "         （1）循环遍历，将500个子进程添加到进程池（相对父进程会阻塞）\\n'\n",
    "         （2）每次执行2个子进程，等一个子进程执行完后，立马启动新的子进程。（相对父进程不阻塞）\\n'\n",
    "        '''\n",
    "        pool.apply_async(test, args=(i,))   #维持执行的进程总数为10，当一个进程执行完后启动一个新进程.\n",
    "    print('test')\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def job(x):\n",
    "    # 使用进程池的时候允许函数将结果返回\n",
    "    return x*x\n",
    "\n",
    "\n",
    "def multicore():\n",
    "    # 定义一个进程池，并声明进程池中进程的个数\n",
    "    pool = mp.Pool(processes=2)\n",
    "    # 将任务放入进程池中, map函数会将job函数作用于range(10)中的每一个元素\n",
    "    res = pool.map(job, range(10))\n",
    "    print(res)\n",
    "    # 使用异步的方式将任务放入进程池中，但一次性只会放入一个任务\n",
    "    res = pool.apply_async(job, (2,))\n",
    "    print(res.get())\n",
    "    multi_res =[pool.apply_async(job, (i,)) for i in range(10)]\n",
    "    print([res.get() for res in multi_res])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    multicore()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 回调函数的使用\n",
    "** 总结来说，回调函数是用来处理目标函数的返回值的，所谓“回调”就是函数执行完成“回头再调用” 目标函数的返回值就是回调函数的输入参数 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 0 executing with 123\n",
      "Callback got: 123\n"
     ]
    }
   ],
   "source": [
    "from random import random\n",
    "from time import sleep\n",
    "from multiprocessing.pool import Pool\n",
    " \n",
    "# result callback function\n",
    "def result_callback(result):\n",
    "    print(f'Callback got: {result}', flush=True)\n",
    " \n",
    "# task executed in a worker process\n",
    "def task(identifier):\n",
    "    # generate a value\n",
    "    # value = random()\n",
    "    value = 123\n",
    "    # report a message\n",
    "    print(f'Task {identifier} executing with {value}', flush=True)\n",
    "    # block for a moment\n",
    "    sleep(1)\n",
    "    # return the generated value\n",
    "    return value\n",
    " \n",
    "# protect the entry point\n",
    "if __name__ == '__main__':\n",
    "    # create and configure the process pool\n",
    "    with Pool() as pool:\n",
    "        # issue tasks to the process pool\n",
    "        result = pool.apply_async(task, args=(0,), callback=result_callback)\n",
    "        # close the process pool\n",
    "        pool.close()\n",
    "        # wait for all tasks to complete\n",
    "        pool.join()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 进程间通信"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def job(q):\n",
    "    res = 0\n",
    "    for i in range(1000):\n",
    "        res += i+i**2+i**3\n",
    "    q.put(res) # queue\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    q = mp.Queue()\n",
    "    p1 = mp.Process(target=job, args=(q,))\n",
    "    p2 = mp.Process(target=job, args=(q,))\n",
    "    p1.start()\n",
    "    p2.start()\n",
    "    p1.join()\n",
    "    p2.join()\n",
    "    res1 = q.get()\n",
    "    res2 = q.get()\n",
    "    print(res1+res2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 进程之间共享内存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 声明一个可以被进程共享的全局变量 i 代表整数，  'd' 表示双精度浮点数， f代表float\n",
    "value = mp.Value('i', 0)\n",
    "# 声明一个可以被进程共享的全局数组，只能是一维数组\n",
    "array = mp.Array('i', [1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "13\n",
      "16\n",
      "19\n",
      "22\n",
      "25\n",
      "28\n",
      "31\n",
      "34\n",
      "37\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "import time\n",
    "\n",
    "def job(v, num, l):\n",
    "    l.acquire()\n",
    "    for _ in range(10):\n",
    "        time.sleep(0.1)\n",
    "        # 通过value.value拿到共享变量的值\n",
    "        v.value += num\n",
    "        print(v.value)\n",
    "    l.release()\n",
    "\n",
    "\n",
    "def multicore():\n",
    "    # 声明一个进程锁对象\n",
    "    l = mp.Lock()\n",
    "    v = mp.Value('i', 0)\n",
    "    # 需要把目标函数，参数，进程锁对象传入进程中\n",
    "    p1 = mp.Process(target=job, args=(v, 1, l))\n",
    "    p2 = mp.Process(target=job, args=(v, 3, l))\n",
    "    p1.start()\n",
    "    p2.start()\n",
    "    p1.join()\n",
    "    p2.join()\n",
    "if __name__ == '__main__':\n",
    "    multicore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "import time\n",
    "\n",
    "def my_counter(shared_v, plock):\n",
    "    plock.acquire()\n",
    "    shared_v.value += 1\n",
    "    plock.release()\n",
    "    time.sleep(0.1)\n",
    "\n",
    "\n",
    "def multicore():\n",
    "    # 声明一个进程锁对象\n",
    "    l = mp.Lock()\n",
    "    v = mp.Value('i', 0)\n",
    "    # 需要把目标函数，参数，进程锁对象传入进程中\n",
    "    pool = mp.Pool(processes = 20)\n",
    "    for i in range(10):\n",
    "        pool.apply_async(my_counter, args=(v, l))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return v.value\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(multicore())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 官方给的样例分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool, TimeoutError\n",
    "import time\n",
    "import os\n",
    "\n",
    "def f(x):\n",
    "    return x*x\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # start 4 worker processes\n",
    "    with Pool(processes=4) as pool:\n",
    "\n",
    "        # print \"[0, 1, 4,..., 81]\"\n",
    "        print(pool.map(f, range(10)))\n",
    "\n",
    "        # print same numbers in arbitrary order\n",
    "        for i in pool.imap_unordered(f, range(10)):\n",
    "            print(i)\n",
    "\n",
    "        # evaluate \"f(20)\" asynchronously\n",
    "        res = pool.apply_async(f, (20,))      # runs in *only* one process\n",
    "        print(res.get(timeout=1))             # prints \"400\"\n",
    "\n",
    "        # evaluate \"os.getpid()\" asynchronously\n",
    "        res = pool.apply_async(os.getpid, ()) # runs in *only* one process\n",
    "        print(res.get(timeout=1))             # prints the PID of that process\n",
    "\n",
    "        # launching multiple evaluations asynchronously *may* use more processes\n",
    "        multiple_results = [pool.apply_async(os.getpid, ()) for i in range(4)]\n",
    "        print([res.get(timeout=1) for res in multiple_results])\n",
    "\n",
    "        # make a single worker sleep for 10 seconds\n",
    "        res = pool.apply_async(time.sleep, (10,))\n",
    "        try:\n",
    "            print(res.get(timeout=1))\n",
    "        except TimeoutError:\n",
    "            print(\"We lacked patience and got a multiprocessing.TimeoutError\")\n",
    "\n",
    "        print(\"For the moment, the pool remains available for more work\")\n",
    "\n",
    "    # exiting the 'with'-block has stopped the pool\n",
    "    print(\"Now the pool is closed and no longer available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "import PIL.Image as Image\n",
    "\n",
    "img_base_path = \"/datassd2/sswang/image_matching/data/isc_data/training_imgs/training\"\n",
    "\n",
    "img_list = os.listdir(img_base_path)\n",
    "img_list = [os.path.join(img_base_path, img_name) for img_name in img_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 个人练习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 定义一个计时器\n",
    "def timer(func):\n",
    "    def func_wrapper(*args, **kwargs):\n",
    "        time_start = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        time_end = time.time()\n",
    "        time_spend = time_end - time_start\n",
    "        print('%s cost time: %.3f s' % (func.__name__, time_spend))\n",
    "        return result\n",
    "    return func_wrapper\n",
    "\n",
    "\n",
    "# 读取单张图片\n",
    "def img_IO(img_path):\n",
    "    img = Image.open(img_path)\n",
    "    img.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 使用单线程读取所有图片\n",
    "@timer\n",
    "def img_IO_singleprocessing(img_list):\n",
    "    counter = 0\n",
    "    for img_path in img_list:\n",
    "        img = Image.open(img_path)\n",
    "        img.close()\n",
    "        counter += 1\n",
    "        \n",
    "    return counter\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    counter = img_IO_singleprocessing(img_list)\n",
    "    print(\"一共读取了{}张图片\".format(counter))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 单个进程读取图片\n",
    "def img_IO_with_ptocessing(img_path, counter, counter_lock):\n",
    "    # print(counter.value)\n",
    "    img = Image.open(img_path)\n",
    "    img.close()\n",
    "    # counter_lock.acquire()\n",
    "    counter.value += 1\n",
    "    # counter_lock.release()\n",
    "\n",
    "\n",
    "# 使用多进程读取图片\n",
    "@timer\n",
    "def img_IO_multiprocessing(img_list, counter, counter_lock):\n",
    "    # 定义一个进程池\n",
    "    pool = mp.Pool(processes = 10)\n",
    "    for i in range(70000):\n",
    "        # pass\n",
    "        pool.apply_async(img_IO_with_ptocessing, args=(img_list[i], counter, counter_lock))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    print(\"一共读取了{}张图片\".format(counter.value))\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    counter = mp.Value('i', 0)\n",
    "    counter_lock = mp.Lock()\n",
    "    img_IO_multiprocessing(img_list, counter, counter_lock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Value, Array\n",
    "\n",
    "def f(n, a):\n",
    "    n.value = 3.1415927\n",
    "    for i in range(len(a)):\n",
    "        a[i] = -a[i]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    num = Value('d', 0.0)\n",
    "    arr = Array('i', range(10))\n",
    "\n",
    "    p = Process(target=f, args=(num, arr))\n",
    "    p.start()\n",
    "    p.join()\n",
    "\n",
    "    print(num.value)\n",
    "    print(arr[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "使用多进程进行数据增强的设计思路：\n",
    "    1. 将数据增强函数封装维一个完整的函数，当多进程的target函数时，可以直接调用\n",
    "    2. 将累加变量设置成为一个进程共享的全局变量，线程拿到累加变量之后先锁定，然后进行累加，最后解锁，之后再进行一次数据增强操作\n",
    "    3. 进程之间需要共享数据，使用进程池的时候，可以使用进程池的map函数，将数据增强函数作用于数据集中的每一个元素\n",
    "\n",
    "对多进程使用效果的评估\n",
    "    1. 让程序IO训练集中的7W张图片，观察时间的差异\n",
    "    2. 通过time.time()函数，计算数据IO的时间\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "img_matching",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
